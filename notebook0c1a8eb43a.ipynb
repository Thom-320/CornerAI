{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "notebook0c1a8eb43a"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdulRId6uxqh",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok bitsandbytes langchain_community pypdf qdrant-client"
      ],
      "metadata": {
        "id": "wCxO4Q9FYVtZ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "from qdrant_client.http.models import PointStruct\n",
        "from tqdm import tqdm\n",
        "import flask\n",
        "from flask import request\n",
        "import threading\n",
        "#from flask_ngrok import run_with_ngrok\n",
        "import multiprocessing\n",
        "from pyngrok import ngrok\n",
        "import json\n",
        "#import pymilvus\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import VectorParams, Distance\n",
        "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "\n",
        "\n",
        "qdrantclient=QdrantClient(path=\"xd.db\")\n",
        "modelsentence=SentenceTransformer(\"BAAI/bge-m3\",device=\"cuda\")\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\",padding_side=\"left\",token=\"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\")\n",
        "modelm=AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\",device_map=\"auto\",load_in_4bit=True,token=\"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\",torch_dtype=\"auto\")\n",
        "\n",
        "\n",
        "\n",
        "app=flask.Flask(\"el diablo\")\n",
        "ngrok.set_auth_token(\"2tznQ0YLZ52mZsTK46WyIjGtq9r_5Lb9fBtTYCPuBER1TsFRf\")\n",
        "public_url = ngrok.connect('5000')\n",
        "dim=1024\n",
        "\n",
        "textarray= lambda x: [(i,j.page_content) for i,j in enumerate(RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100).split_documents(x))]\n",
        "to_emb= lambda y:modelsentence.encode([y],normalize_embeddings=True)\n",
        "prompttemplate=[ {\"role\":\"system\",\"content\":\"responde la pregunta dado el contexto en castellano. contexto:\"},\n",
        "    {\"role\":\"user\",\"content\":\"pregunta:\"}\n",
        "    ]\n",
        "\n",
        "\n",
        "audiomodel=AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large-v3-turbo\",torch_dtype=\"auto\",device_map=\"auto\",load_in_4bit=True)\n",
        "\n",
        "audioprocesor=AutoProcessor.from_pretrained(\"openai/whisper-large-v3-turbo\")\n",
        "pipelinedeabiertoai=pipeline(\"automatic-speech-recognition\",model=audiomodel,tokenizer=audioprocesor.tokenizer,feature_extractor=audioprocesor.feature_extractor)\n",
        "\n",
        "#result=pipelinedeabiertoai(\"audiopendejo.mp3\",return_timestamps=True)\n",
        "def search(prompt,collection):\n",
        "  embedding=to_emb(prompt).tolist()[0]\n",
        "  searchl=qdrantclient.search(collection,embedding,limit=4)\n",
        "  searchl=\"\\n\".join([i.payload[\"text\"] for i in searchl])\n",
        "  return searchl\n",
        "\n",
        "#{\"json\":{\"collection\":\"any\"},\"file\":pdf}\n",
        "@app.route(\"/upload\",methods=[\"POST\"])\n",
        "def upload():\n",
        "  data=[]\n",
        "  #request.files[\"json\"].save(\"jsond.json\")\n",
        "  datapost=json.loads(request.files[\"json\"].read())\n",
        "\n",
        "  collection=datapost[\"collection\"]\n",
        "\n",
        "\n",
        "\n",
        "  #print(request.files)\n",
        "  print(\"ichi\")\n",
        "\n",
        "  request.files[\"file\"].save(\"importpdf.pdf\")\n",
        "  pdf=PyPDFLoader(\"importpdf.pdf\").load()\n",
        "  print(\"ni\")\n",
        "  if not qdrantclient.collection_exists(collection):\n",
        "    qdrantclient.create_collection(collection,VectorParams(size=1024,distance=Distance.COSINE))\n",
        "    print(\"collection not found, creating new collection\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #if milvusclient.has_collection(collection):\n",
        "  textarrayc=textarray(pdf)\n",
        "  print(\"san\")\n",
        "  for i,j in tqdm(textarrayc):\n",
        "      embedding=to_emb(j).tolist()[0]\n",
        "      tupled=PointStruct(id=i,vector=embedding,payload={\"text\":j})\n",
        "      data.append(tupled)\n",
        "\n",
        "  req=qdrantclient.upsert(collection,data)\n",
        "  print(req)\n",
        "\n",
        "\n",
        "\n",
        "  #save file\n",
        "\n",
        "\n",
        "\n",
        "  return \"sucess\"\n",
        "\n",
        "@app.route(\"/inference\",methods=[\"POST\"])\n",
        "#json={\"prompt\":anyprompt,\"collection\":anycollection}\n",
        "def inference():\n",
        "  jsonq=json.loads(request.files[\"json\"].read())\n",
        "\n",
        "  request.files[\"audio\"].save(\"audioprocess.mp3\")\n",
        "  promptin=pipelinedeabiertoai(\"audioprocess.mp3\",return_timestamps=True)[\"text\"]\n",
        "  print(\"proms:\"+promptin)\n",
        "  promptcol=jsonq[\"collection\"]\n",
        "  promptc=prompttemplate\n",
        "\n",
        "  promptc[1][\"content\"]=\"pregunta:\"+promptin\n",
        "  promptc[0][\"content\"]=promptc[0][\"content\"]+search(promptin,promptcol)\n",
        "  tokenized=tokenizer.apply_chat_template(promptc,add_generation_prompt=True,return_tensors=\"pt\").to(\"cuda\")\n",
        "  lenn=tokenized.size()[1]\n",
        "  inferencee_ids=modelm.generate(tokenized,max_new_tokens=5000)\n",
        "  decodee=tokenizer.batch_decode(inferencee_ids[:,lenn::],skip_special_tokens=True,do_sample=True,max_new_tokens=1000)\n",
        "  return decodee[0]\n",
        "\n",
        "@app.route(\"/audio\",methods=[\"POST\"])\n",
        "def audio():\n",
        "  audio=request.files[\"file\"]\n",
        "  audio.save(\"audiopendejo.mp3\")\n",
        "  return \"estas baneado\"\n",
        "#process=multiprocessing.Process(target=app.run)\n",
        "#process.start()\n",
        "print(public_url)\n",
        "app.run(host=\"0.0.0.0\", port=5000, threaded=True)\n"
      ],
      "metadata": {
        "id": "_CSHBAGmNmtg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-10T21:29:38.059778Z",
          "iopub.execute_input": "2025-03-10T21:29:38.060106Z",
          "iopub.status.idle": "2025-03-10T21:39:59.677721Z",
          "shell.execute_reply.started": "2025-03-10T21:29:38.060083Z",
          "shell.execute_reply": "2025-03-10T21:39:59.67676Z"
        },
        "outputId": "f6a774cb-6368-45e8-fefc-52bb598864e6",
        "colab": {
          "referenced_widgets": [
            "40d75054dee74dcab75863ee85b71cff",
            "b8633d09eb1d41fdb304c9b77f16676b",
            "635792ae008242378619807a34930590",
            "1265f5b321e84c8e833aa7d107822458",
            "d2848609393c457e962946f88a318b21",
            "e1c8bf3c069f44dd9984d2fd223b98dc",
            "bbd396c0653e41358793391f04b4da04",
            "89ca2d292e7446d09603b1cbba2094e0",
            "c61afbafa08f45f88e8be00e9fb331b2",
            "4c3de0a50e10416b8a79417a1be4f152",
            "dcc48d72dc054d38980cdb63f932b672",
            "e6181f7e276e404ea84f6778168001c9",
            "55aea3cb45334e889dd6f84ef01e7ef5",
            "73bc1b6a2eb44f819c300a888c0bb0da",
            "fcb8849c59af4a0c96ad3dfd7eb68dec",
            "f96b3e54009b4b1693bc825bd5e02aeb",
            "c210fe8463e94169a77c5ae46580a424",
            "cd1a12d4f4e84471bce12c01acb1ba46",
            "bb16f3c82b8a49f4aec7c3cbd654ba25",
            "54c9da67744247079b0d01030e5003cc",
            "b954695533d84af1b6be1a463a52c982",
            "750452372bbf434fb415e210fbc4654c",
            "3cbe2d29b08e44e5ba42b05e519dcd2f",
            "95dd086f5f5e451db1e7705302f1337f",
            "e53360a679384974863aa58f32764b46",
            "7aaec3bc10404671a5d88b4add42cc90",
            "4a5114e401434073b609110bb2dac05d",
            "3a19ff8a69bc4cf785880b72c9ecb529",
            "6dd17a2c79ec473786e15a9c061e7321",
            "07b2c2f55f404086968e1acfc508208b",
            "84b12b433b05450b970ccacd5312fbd8",
            "d83418cb8fd844e7b8a9b303a492a499",
            "58ac68d56df544e58045aa25cdb456ef",
            "c8d698aed4d74bb2bf0cdc53acfc5c24",
            "d412695a6be04344aac6c51f39dfd815",
            "39e4840e777b4e1c8214fe06cc3ec3f3",
            "2ac856afd0f4474eac9e1a7ff60c9e9c",
            "4b00fff836824cbba6f6590aefb62802",
            "c384ea9e41de468eaeaf80cade1283fa",
            "66e9591c850645d8adb14b9a736f3553",
            "4324209c8d90462f92cd83e4c1f25ff1",
            "ae496893a4034fcd8043c8b33c83ba85",
            "dc1728eb32ae4d369dd8265e59b77786",
            "d495734f0d1642529b55c5e8a264e707",
            "cc9b7110544740d4bc58684f12a75ca4",
            "8504e303d43f4445a634055e1a131b9a",
            "77c80ec0dae04cd199925edd315bd2d7",
            "bf4980cc03614b06868e4712d66ba8e6",
            "cb12f5e6602348b4ad86ca8129028591",
            "149dfaa0972a431f8d679c4cfa34ae66",
            "394d70d4163440d3a68afeb2119fb3d6",
            "fb54e18ffb254d5db18db10744d607f6",
            "02f71e037f8b45de99dde4c667178136",
            "489bc0e00eeb478993fd80c5c90ace71",
            "9088e923bce94fb998f6368881e42972",
            "f61ad78d2aa2490b8813fd843848e22e",
            "15b69951c7fd48e7b382cae8875b9b83",
            "1cb941a34c474b219bc089d29160687e",
            "cbb7de57a16b42098ae060f9752b0b46",
            "e618213040394687aede5ec30c58dc77"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40d75054dee74dcab75863ee85b71cff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8633d09eb1d41fdb304c9b77f16676b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/15.8k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "635792ae008242378619807a34930590"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1265f5b321e84c8e833aa7d107822458"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2848609393c457e962946f88a318b21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1c8bf3c069f44dd9984d2fd223b98dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbd396c0653e41358793391f04b4da04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89ca2d292e7446d09603b1cbba2094e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c61afbafa08f45f88e8be00e9fb331b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3de0a50e10416b8a79417a1be4f152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcc48d72dc054d38980cdb63f932b672"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6181f7e276e404ea84f6778168001c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55aea3cb45334e889dd6f84ef01e7ef5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73bc1b6a2eb44f819c300a888c0bb0da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcb8849c59af4a0c96ad3dfd7eb68dec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f96b3e54009b4b1693bc825bd5e02aeb"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c210fe8463e94169a77c5ae46580a424"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd1a12d4f4e84471bce12c01acb1ba46"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "                                                                                                    \r",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb16f3c82b8a49f4aec7c3cbd654ba25"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/1.62G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54c9da67744247079b0d01030e5003cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/3.77k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b954695533d84af1b6be1a463a52c982"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "750452372bbf434fb415e210fbc4654c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cbe2d29b08e44e5ba42b05e519dcd2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95dd086f5f5e451db1e7705302f1337f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/2.71M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e53360a679384974863aa58f32764b46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aaec3bc10404671a5d88b4add42cc90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a5114e401434073b609110bb2dac05d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a19ff8a69bc4cf785880b72c9ecb529"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dd17a2c79ec473786e15a9c061e7321"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "NgrokTunnel: \"https://f4ef-34-135-184-28.ngrok-free.app\" -> \"http://localhost:5000\"\n * Serving Flask app 'el diablo'\n * Debug mode: off\nichi\nni\ncollection not found, creating new collection\nsan\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  0%|          | 0/29 [00:00<?, ?it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07b2c2f55f404086968e1acfc508208b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "  3%|▎         | 1/29 [00:00<00:14,  1.91it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84b12b433b05450b970ccacd5312fbd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d83418cb8fd844e7b8a9b303a492a499"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 10%|█         | 3/29 [00:00<00:04,  5.52it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58ac68d56df544e58045aa25cdb456ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8d698aed4d74bb2bf0cdc53acfc5c24"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 17%|█▋        | 5/29 [00:00<00:02,  8.47it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d412695a6be04344aac6c51f39dfd815"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39e4840e777b4e1c8214fe06cc3ec3f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ac856afd0f4474eac9e1a7ff60c9e9c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 28%|██▊       | 8/29 [00:00<00:01, 12.35it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b00fff836824cbba6f6590aefb62802"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c384ea9e41de468eaeaf80cade1283fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66e9591c850645d8adb14b9a736f3553"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 38%|███▊      | 11/29 [00:01<00:01, 15.13it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4324209c8d90462f92cd83e4c1f25ff1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae496893a4034fcd8043c8b33c83ba85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc1728eb32ae4d369dd8265e59b77786"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 48%|████▊     | 14/29 [00:01<00:00, 17.64it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d495734f0d1642529b55c5e8a264e707"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc9b7110544740d4bc58684f12a75ca4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8504e303d43f4445a634055e1a131b9a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 59%|█████▊    | 17/29 [00:01<00:00, 19.20it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77c80ec0dae04cd199925edd315bd2d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf4980cc03614b06868e4712d66ba8e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb12f5e6602348b4ad86ca8129028591"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 69%|██████▉   | 20/29 [00:01<00:00, 20.73it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "149dfaa0972a431f8d679c4cfa34ae66"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "394d70d4163440d3a68afeb2119fb3d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb54e18ffb254d5db18db10744d607f6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 79%|███████▉  | 23/29 [00:01<00:00, 21.83it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02f71e037f8b45de99dde4c667178136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "489bc0e00eeb478993fd80c5c90ace71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9088e923bce94fb998f6368881e42972"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": " 90%|████████▉ | 26/29 [00:01<00:00, 22.73it/s]",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f61ad78d2aa2490b8813fd843848e22e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15b69951c7fd48e7b382cae8875b9b83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cb941a34c474b219bc089d29160687e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 29/29 [00:01<00:00, 16.31it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "operation_id=0 status=<UpdateStatus.COMPLETED: 'completed'>\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\nDue to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:446: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "proms: Puede suministrarme los entregables y las fechas respectivas.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbb7de57a16b42098ae060f9752b0b46"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "<ipython-input-1-68db06d44d79>:48: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n  searchl=qdrantclient.search(collection,embedding,limit=4)\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "proms: Puede suministrarme los entregables y las fechas respectivas.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e618213040394687aede5ec30c58dc77"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "<ipython-input-1-68db06d44d79>:48: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n  searchl=qdrantclient.search(collection,embedding,limit=4)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "app=flask.Flask(\"el diablo\")\n",
        "ngrok.set_auth_token(\"2tznQ0YLZ52mZsTK46WyIjGtq9r_5Lb9fBtTYCPuBER1TsFRf\")\n",
        "public_url = ngrok.connect('5000')\n",
        "dim=1024\n",
        "\n",
        "textarray= lambda x: [(i,j.page_content) for i,j in enumerate(RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100).split_documents(x))]\n",
        "to_emb= lambda y:modelsentence.encode([y],normalize_embeddings=True)\n",
        "prompttemplate=[ {\"role\":\"system\",\"content\":\"responde la pregunta dado el contexto en castellano en forma consisa y lo mas resumida posible. contexto:\"},\n",
        "    {\"role\":\"user\",\"content\":\"pregunta:\"}\n",
        "    ]\n",
        "\n",
        "\n",
        "audiomodel=AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large-v3-turbo\",torch_dtype=\"auto\",device_map=\"auto\",load_in_4bit=True)\n",
        "\n",
        "audioprocesor=AutoProcessor.from_pretrained(\"openai/whisper-large-v3-turbo\")\n",
        "pipelinedeabiertoai=pipeline(\"automatic-speech-recognition\",model=audiomodel,tokenizer=audioprocesor.tokenizer,feature_extractor=audioprocesor.feature_extractor)\n",
        "\n",
        "#result=pipelinedeabiertoai(\"audiopendejo.mp3\",return_timestamps=True)\n",
        "def search(prompt,collection):\n",
        "  embedding=to_emb(prompt).tolist()[0]\n",
        "  searchl=qdrantclient.search(collection,embedding,limit=4)\n",
        "  searchl=\"\\n\".join([i.payload[\"text\"] for i in searchl])\n",
        "  return searchl\n",
        "\n",
        "#{\"json\":{\"collection\":\"any\"},\"file\":pdf}\n",
        "@app.route(\"/upload\",methods=[\"POST\"])\n",
        "def upload():\n",
        "  data=[]\n",
        "  #request.files[\"json\"].save(\"jsond.json\")\n",
        "  datapost=json.loads(request.files[\"json\"].read())\n",
        "\n",
        "  collection=datapost[\"collection\"]\n",
        "\n",
        "\n",
        "\n",
        "  #print(request.files)\n",
        "  print(\"ichi\")\n",
        "\n",
        "  request.files[\"file\"].save(\"importpdf.pdf\")\n",
        "  pdf=PyPDFLoader(\"importpdf.pdf\").load()\n",
        "  print(\"ni\")\n",
        "  if not qdrantclient.collection_exists(collection):\n",
        "    qdrantclient.create_collection(collection,VectorParams(size=1024,distance=Distance.COSINE))\n",
        "    print(\"collection not found, creating new collection\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #if milvusclient.has_collection(collection):\n",
        "  textarrayc=textarray(pdf)\n",
        "  print(\"san\")\n",
        "  for i,j in tqdm(textarrayc):\n",
        "      embedding=to_emb(j).tolist()[0]\n",
        "      tupled=PointStruct(id=i,vector=embedding,payload={\"text\":j})\n",
        "      data.append(tupled)\n",
        "\n",
        "  req=qdrantclient.upsert(collection,data)\n",
        "  print(req)\n",
        "\n",
        "\n",
        "\n",
        "  #save file\n",
        "\n",
        "\n",
        "\n",
        "  return \"sucess\"\n",
        "\n",
        "@app.route(\"/inference\",methods=[\"POST\"])\n",
        "#json={\"prompt\":anyprompt,\"collection\":anycollection}\n",
        "def inference():\n",
        "  jsonq=json.loads(request.files[\"json\"].read())\n",
        "\n",
        "  request.files[\"audio\"].save(\"audioprocess.mp3\")\n",
        "  promptin=pipelinedeabiertoai(\"audioprocess.mp3\",return_timestamps=True)[\"text\"]\n",
        "  print(\"proms:\"+promptin)\n",
        "  promptcol=jsonq[\"collection\"]\n",
        "  promptc=prompttemplate\n",
        "\n",
        "  promptc[1][\"content\"]=\"pregunta:\"+promptin\n",
        "  promptc[0][\"content\"]=promptc[0][\"content\"]+search(promptin,promptcol)\n",
        "  tokenized=tokenizer.apply_chat_template(promptc,add_generation_prompt=True,return_tensors=\"pt\").to(\"cuda\")\n",
        "  lenn=tokenized.size()[1]\n",
        "  inferencee_ids=modelm.generate(tokenized,max_new_tokens=100)\n",
        "  decodee=tokenizer.batch_decode(inferencee_ids[:,lenn::],skip_special_tokens=True,do_sample=True,max_new_tokens=1000)\n",
        "  return decodee[0]\n",
        "\n",
        "@app.route(\"/audio\",methods=[\"POST\"])\n",
        "def audio():\n",
        "  audio=request.files[\"file\"]\n",
        "  audio.save(\"audiopendejo.mp3\")\n",
        "  return \"estas baneado\"\n",
        "#process=multiprocessing.Process(target=app.run)\n",
        "#process.start()\n",
        "print(public_url)\n",
        "app.run(host=\"0.0.0.0\", port=5000, threaded=True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-10T21:41:02.530243Z",
          "iopub.execute_input": "2025-03-10T21:41:02.530596Z",
          "iopub.status.idle": "2025-03-10T21:58:26.385767Z",
          "shell.execute_reply.started": "2025-03-10T21:41:02.530566Z",
          "shell.execute_reply": "2025-03-10T21:58:26.384653Z"
        },
        "id": "oO0sG6oRE9yI",
        "outputId": "45cdcddf-b275-46b7-e242-f396cc239f5a",
        "colab": {
          "referenced_widgets": [
            "fadc349d748a44bdb4f1a71266f4b50b"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\nDevice set to use cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "NgrokTunnel: \"https://42c3-34-135-184-28.ngrok-free.app\" -> \"http://localhost:5000\"\n * Serving Flask app 'el diablo'\n * Debug mode: off\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "proms: Puede suministrarme los entregables y las fechas respectivas.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fadc349d748a44bdb4f1a71266f4b50b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "<ipython-input-3-b76b35fff1b2>:21: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n  searchl=qdrantclient.search(collection,embedding,limit=4)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline"
      ],
      "metadata": {
        "id": "CGw36Soh9NMG",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "qdrantclient.close()"
      ],
      "metadata": {
        "id": "_oQXi3BcITE0",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "qdrantclient.create_collection(\"lol\",VectorParams(size=1024,distance=Distance.COSINE))"
      ],
      "metadata": {
        "id": "4LwnP5vpAEYg",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(to_emb(\"no se\").tolist()[0]))\n",
        "#qdrantclient.close()"
      ],
      "metadata": {
        "id": "Xn9yFFEDSpWV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbcDEAHRc9uq",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"por cuales cosas podre faltar a una clase?\""
      ],
      "metadata": {
        "id": "biUjvi9HaWlr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "embedding=to_emb(query).tolist()[0]\n"
      ],
      "metadata": {
        "id": "nipeEQq7XFLH",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#search\n",
        "print(qdrantclient.search(\"test\",embedding,limit=4)[0].payload[\"text\"])"
      ],
      "metadata": {
        "id": "H5cqoAFyXNyE",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "json.loads(\"jsond.json\")"
      ],
      "metadata": {
        "id": "6-yBASZQ2jzL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#process.terminate()\n",
        "#end ngrok tunnel\n",
        "ngrok.disconnect(public_url.public_url)\n"
      ],
      "metadata": {
        "id": "3nLRt5a2Ypfq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-10T21:40:14.915673Z",
          "iopub.execute_input": "2025-03-10T21:40:14.91637Z",
          "iopub.status.idle": "2025-03-10T21:40:14.920125Z",
          "shell.execute_reply.started": "2025-03-10T21:40:14.916338Z",
          "shell.execute_reply": "2025-03-10T21:40:14.919246Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "a2fGr0z2RjTU",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58t23cDT9Wv5",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(public_url.public_url)\n",
        "objd={\"collection\":\"dou\"}\n",
        "filess={\"file\":open(\"dr.gif\",\"rb\")}"
      ],
      "metadata": {
        "id": "QavjQY_6dYHj",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OE3ZfSQTmnux",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#test=requests.get(\"http://127.0.0.1:5000/inference\")\n",
        "#headers = {\n",
        "    #'Content-type':'application/json',\n",
        "    #'Accept':'application/json'\n",
        "#}\n",
        "\n",
        "test=requests.post(public_url.public_url+\"/upload\",data=objd,files=filess)"
      ],
      "metadata": {
        "id": "oYiaIW-aR-tN",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(test.text)"
      ],
      "metadata": {
        "id": "l6iUvTEoSXe-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "audiomodel=AutoModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-large-v3-turbo\",torch_dtype=\"auto\",device_map=\"auto\",load_in_4bit=True)\n",
        "\n",
        "audioprocesor=AutoProcessor.from_pretrained(\"openai/whisper-large-v3-turbo\")\n",
        "pipelinedeabiertoai=pipeline(\"automatic-speech-recognition\",model=audiomodel,tokenizer=audioprocesor.tokenizer,feature_extractor=audioprocesor.feature_extractor)\n",
        "\n",
        "result=pipelinedeabiertoai(\"audiopendejo.mp3\",return_timestamps=True)"
      ],
      "metadata": {
        "id": "rDEGgzbM9jqr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "P5gNLnjR_WV-",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b_rKdSESAZ4I"
      }
    }
  ]
}